# vim: set ts=4 softtabstop=0 sw=4 si fileencoding=utf-8:
#
# Authors:     TS
# Maintainers: TS
# Copyright:   2020, HRDAG, GPL v2 or later
# =========================================
# cpdp_ocr/6a_structural_parsing/arrest-reports/src/classify.R

library(pacman)
pacman::p_load(argparse, feather, dplyr, rlang, topicmodels, randomForest,
               tidytext, tidyr, purrr, stringr, stringdist, readr)


parser <- ArgumentParser()
parser$add_argument("--input")
parser$add_argument("--topics", default = "output/lda-model.rds")
parser$add_argument("--classifier", default = "output/model-classify-section.rds")
parser$add_argument("--output")
args <- parser$parse_args()

####

pos_funs <- new.env()
sys.source("src/fns-position-label.R", envir = pos_funs)
is_legible <- function(txt)
    str_length(str_trim(str_replace_all(txt, "[^a-zA-Z0-9 ]", ""))) > 1

###

topic_mod <- readRDS(args$topics)

arrest_reports <- read_feather(args$input) %>%
    filter(page_classification == "ARREST Report")

arr_lines <- arrest_reports %>%
    mutate(height_bound = ifelse(height_bound > 2000, 1, height_bound)) %>%
    arrange(pdf_id, page_num, block_num, par_num, line_num, word_num) %>%
    group_by(pdf_id, filename, page_num, block_num, par_num, line_num) %>%
    summarise(text = paste(text, collapse = " "),
              line_top = min(top_bound),
              line_bottom = max(top_bound + height_bound),
              line_left = min(left_bound),
              line_right = max(left_bound + width_bound),
              .groups = "drop")

position_features <- pos_funs$docs2label(arr_lines) %>%
    rename(p_lab = section)

arr_dtm <- arr_lines %>%
    unnest_tokens(word, text) %>%
    filter(word %in% topic_mod@terms) %>%
    mutate(identifier = paste(pdf_id, page_num, block_num,
                              par_num, line_num, sep = "_")) %>%
    count(identifier, word) %>%
    cast_dtm(identifier, word, n)

arr_topics <- topicmodels::posterior(topic_mod, newdata = arr_dtm)
arr_topics_df <- as_tibble(arr_topics$topics, rownames = "identifier") %>%
    set_names(~paste0("t_", .)) %>%
    separate(t_identifier,
             into = c("pdf_id", "page_num", "block_num",
                      "par_num", "line_num"), sep = "_") %>%
    mutate_at(vars(pdf_id, contains("_num")), as.integer)

## other hints

processed_arr_lines <- arr_lines %>%
    left_join(position_features,
              by = c("pdf_id", "filename",
                     "page_num", "block_num", "par_num", "line_num")) %>%
    left_join(arr_topics_df,
              by = c("pdf_id", "page_num",
                     "block_num", "par_num", "line_num")) %>%
    mutate(p_lab = replace_na(p_lab, "NODATA")) %>%
    mutate_at(vars(starts_with("t_")), ~replace_na(., 0)) %>%
    mutate(re_facts = str_detect(text, "^.{0,10}facts"),
           re_probable = str_detect(text, "probable"),
           re_substantiate = str_detect(text, "substantiate"),
           re_name = str_detect(text, "^Name"),
           re_inj = str_detect(text, "Injured\\?"),
           re_dec = str_detect(text, "Deceased\\?"),
           re_attest = str_detect(text, "^ATTESTING"),
           re_hf = str_detect(text, "^Holding Facility"),
           re_vis = str_detect(text, "^NO VISITORS"),
           re_warr = str_detect(text, "^NO WARRANT"),
           re_prop = str_detect(text, "^Confiscated Properties"),
           re_ardt = str_detect(text, "^Arrest Date"),
           re_trr = str_detect(text, "TRR"),
           re_crtdt = str_detect(text, "^Desired Court Date"),
           re_pgb = str_detect(text, "^Print Generated By")) %>%
    mutate_at(vars(starts_with("re_")), as.numeric) %>%
    filter(line_right > 110, is_legible(text)) %>%
    select(-text)

processed_arr_lines <- processed_arr_lines %>%
    arrange(pdf_id, page_num, line_top, block_num, par_num, line_num) %>%
    group_by(pdf_id) %>%
    mutate(last_page = lag(page_num, 1)) %>%
    replace_na(list(last_page = 0)) %>%
    mutate(new_document = case_when(
            last_page == 0 ~ TRUE,
            page_num > last_page + 1 ~ TRUE,
            TRUE ~ FALSE
        )) %>%
    ungroup %>%
    mutate(docid = cumsum(new_document)) %>%
    select(-new_document, -last_page) %>%
    select(pdf_id, filename, docid, everything())

processed_arr_lines <- processed_arr_lines %>%
    group_by(docid) %>%
    mutate(across(starts_with("re_"), cumsum, .names = "cum_{col}")) %>%
    ungroup

processed_arr_lines <- processed_arr_lines %>%
    arrange(docid, page_num, line_top, block_num, par_num, line_num) %>%
    group_by(docid, page_num) %>%
    mutate(line_gap = line_top - lag(line_bottom, 1)) %>%
    replace_na(list(line_gap = 0)) %>%
    ungroup

processed_arr_lines <- processed_arr_lines %>%
    mutate(identifier = paste(docid, page_num, block_num, par_num, line_num,
                              sep = "_"))

classifier <- readRDS(args$classifier)
system.time(
bloop <- processed_arr_lines %>%
    mutate(label = predict(classifier, newdata = .))
)

bloop %>%
    select(pdf_id, docid, filename, ends_with("_num"), label) %>%
    left_join(arr_lines,
              by = c("pdf_id", "filename", "page_num",
                     "block_num", "par_num", "line_num"))
